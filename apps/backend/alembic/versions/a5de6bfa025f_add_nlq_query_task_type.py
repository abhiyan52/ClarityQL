"""Add NLQ_QUERY task type

Revision ID: a5de6bfa025f
Revises: e186c6ae1322
Create Date: 2026-02-07 13:55:27.390306

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'a5de6bfa025f'
down_revision: Union[str, None] = 'e186c6ae1322'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Step 1: Add new enum value to task_type (uppercase to match Python enum)
    op.execute("ALTER TYPE task_type ADD VALUE IF NOT EXISTS 'NLQ_QUERY'")
    
    # Step 2: Migrate existing lowercase enum values to uppercase
    # This ensures consistency between database and Python code
    op.execute("""
        UPDATE tasks 
        SET task_type = 'DOCUMENT_INGESTION' 
        WHERE task_type = 'document_ingestion'
    """)
    op.execute("""
        UPDATE tasks 
        SET task_type = 'EMBEDDING_GENERATION' 
        WHERE task_type = 'embedding_generation'
    """)
    op.execute("""
        UPDATE tasks 
        SET task_type = 'DOCUMENT_DELETION' 
        WHERE task_type = 'document_deletion'
    """)
    
    # Step 3: Add new uppercase enum values
    op.execute("ALTER TYPE task_type ADD VALUE IF NOT EXISTS 'DOCUMENT_INGESTION'")
    op.execute("ALTER TYPE task_type ADD VALUE IF NOT EXISTS 'EMBEDDING_GENERATION'")
    op.execute("ALTER TYPE task_type ADD VALUE IF NOT EXISTS 'DOCUMENT_DELETION'")
    
    op.drop_table('celery_taskmeta')
    op.drop_table('celery_tasksetmeta')
    op.alter_column('documents', 'processing_status',
               existing_type=postgresql.ENUM('uploaded', 'parsing', 'parsed', 'chunking', 'chunked', 'embedding', 'ready', 'failed', name='document_processing_status'),
               comment='Current stage in the ingestion pipeline',
               existing_nullable=False,
               existing_server_default=sa.text("'uploaded'::document_processing_status"))
    op.alter_column('documents', 'processing_error',
               existing_type=sa.TEXT(),
               comment='Error message if processing failed',
               existing_nullable=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('documents', 'processing_error',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Error message if processing failed',
               existing_nullable=True)
    op.alter_column('documents', 'processing_status',
               existing_type=postgresql.ENUM('uploaded', 'parsing', 'parsed', 'chunking', 'chunked', 'embedding', 'ready', 'failed', name='document_processing_status'),
               comment=None,
               existing_comment='Current stage in the ingestion pipeline',
               existing_nullable=False,
               existing_server_default=sa.text("'uploaded'::document_processing_status"))
    op.create_table('celery_tasksetmeta',
    sa.Column('id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('taskset_id', sa.VARCHAR(length=155), autoincrement=False, nullable=True),
    sa.Column('result', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('date_done', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('celery_tasksetmeta_pkey')),
    sa.UniqueConstraint('taskset_id', name=op.f('celery_tasksetmeta_taskset_id_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.create_table('celery_taskmeta',
    sa.Column('id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('task_id', sa.VARCHAR(length=155), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('result', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('date_done', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('traceback', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('name', sa.VARCHAR(length=155), autoincrement=False, nullable=True),
    sa.Column('args', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('kwargs', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('worker', sa.VARCHAR(length=155), autoincrement=False, nullable=True),
    sa.Column('retries', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('queue', sa.VARCHAR(length=155), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('celery_taskmeta_pkey')),
    sa.UniqueConstraint('task_id', name=op.f('celery_taskmeta_task_id_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    # ### end Alembic commands ###
